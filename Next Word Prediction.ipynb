{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee81a4d6",
   "metadata": {},
   "source": [
    "# LGM VIP in Data Science\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# AUTHOR : Tanmay Sinha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680bfa14",
   "metadata": {},
   "source": [
    "# (03) ADVANCED LEVEL TASK\n",
    "\n",
    "## (2) Next Word Prediction :-\n",
    "\n",
    "\n",
    "### Using Tensorflow and Keras library train a RNN, to predict the next word.\n",
    "\n",
    "### Dataset Link :\n",
    "\n",
    "https://drive.google.com/file/d/1GeUzNVqiixXHnTl8oNiQ2W3CynX_lsu2/view\n",
    "\n",
    "### For problem statements and guidance\n",
    "\n",
    "### Watch Tutorial from here :-\n",
    "\n",
    "https://youtu.be/CBCfOTePVPo :\n",
    "\n",
    "\n",
    "https://thecleverprogrammer.com/2020/07/20/next-word-prediction-model/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd9802",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "Most of the keyboards in smartphones give next word prediction features; google also uses next word prediction based on our browsing history. So a preloaded data is also stored in the keyboard function of our smartphones to predict the next word correctly. In this article, we will train a Deep Learning model for next word prediction using Python. We will use the Tensorflow and Keras library in Python for next word prediction model.\n",
    "\n",
    "## Problem Statement:\n",
    "Using Tensorflow and Keras library train a RNN, to predict the next word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de481c",
   "metadata": {},
   "source": [
    "# Importing necessary libraries and loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b574d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\python\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: tqdm in d:\\python\\lib\\site-packages (from nltk) (4.62.1)\n",
      "Requirement already satisfied: click in d:\\python\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in d:\\python\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\python\\lib\\site-packages (from nltk) (2021.10.23)\n",
      "Requirement already satisfied: colorama in d:\\python\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6836c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0d6dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length:\t 581888\n"
     ]
    }
   ],
   "source": [
    "#loading the dataset\n",
    "text = open('1661-0.txt',encoding='UTF-8').read().lower()\n",
    "print('corpus length:\\t', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3114071",
   "metadata": {},
   "source": [
    "## Splitting the dataset into each word in order but without the presence of some special characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8b2c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " 's',\n",
       " 'the',\n",
       " 'adventures',\n",
       " 'of',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'by',\n",
       " 'arthur',\n",
       " 'conan',\n",
       " 'doyle',\n",
       " 'this',\n",
       " 'ebook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever',\n",
       " 'you',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're',\n",
       " 'use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'license',\n",
       " 'included',\n",
       " 'with',\n",
       " 'this',\n",
       " 'ebook',\n",
       " 'or',\n",
       " 'online',\n",
       " 'at',\n",
       " 'www',\n",
       " 'gutenberg',\n",
       " 'net',\n",
       " 'title',\n",
       " 'the',\n",
       " 'adventures',\n",
       " 'of',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'author',\n",
       " 'arthur',\n",
       " 'conan',\n",
       " 'doyle',\n",
       " 'release',\n",
       " 'date',\n",
       " 'november',\n",
       " '29',\n",
       " '2002',\n",
       " 'ebook',\n",
       " '1661',\n",
       " 'last',\n",
       " 'updated',\n",
       " 'may',\n",
       " '20',\n",
       " '2019',\n",
       " 'language',\n",
       " 'english',\n",
       " 'character',\n",
       " 'set',\n",
       " 'encoding',\n",
       " 'utf',\n",
       " '8',\n",
       " 'start',\n",
       " 'of',\n",
       " 'this',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'the',\n",
       " 'adventures',\n",
       " 'of',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'produced',\n",
       " 'by',\n",
       " 'an',\n",
       " 'anonymous',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'volunteer',\n",
       " 'and',\n",
       " 'jose',\n",
       " 'menendez',\n",
       " 'cover',\n",
       " 'the',\n",
       " 'adventures',\n",
       " 'of',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'by',\n",
       " 'arthur',\n",
       " 'conan',\n",
       " 'doyle',\n",
       " 'contents',\n",
       " 'i',\n",
       " 'a',\n",
       " 'scandal',\n",
       " 'in',\n",
       " 'bohemia',\n",
       " 'ii',\n",
       " 'the',\n",
       " 'red',\n",
       " 'headed',\n",
       " 'league',\n",
       " 'iii',\n",
       " 'a',\n",
       " 'case',\n",
       " 'of',\n",
       " 'identity',\n",
       " 'iv',\n",
       " 'the',\n",
       " 'boscombe',\n",
       " 'valley',\n",
       " 'mystery',\n",
       " 'v',\n",
       " 'the',\n",
       " 'five',\n",
       " 'orange',\n",
       " 'pips',\n",
       " 'vi',\n",
       " 'the',\n",
       " 'man',\n",
       " 'with',\n",
       " 'the',\n",
       " 'twisted',\n",
       " 'lip',\n",
       " 'vii',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'blue',\n",
       " 'carbuncle',\n",
       " 'viii',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'speckled',\n",
       " 'band',\n",
       " 'ix',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'engineer',\n",
       " 's',\n",
       " 'thumb',\n",
       " 'x',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'noble',\n",
       " 'bachelor',\n",
       " 'xi',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'beryl',\n",
       " 'coronet',\n",
       " 'xii',\n",
       " 'the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'copper',\n",
       " 'beeches',\n",
       " 'i',\n",
       " 'a',\n",
       " 'scandal',\n",
       " 'in',\n",
       " 'bohemia',\n",
       " 'i',\n",
       " 'to',\n",
       " 'sherlock',\n",
       " 'holmes',\n",
       " 'she',\n",
       " 'is',\n",
       " 'always',\n",
       " '_the_',\n",
       " 'woman',\n",
       " 'i',\n",
       " 'have',\n",
       " 'seldom',\n",
       " 'heard',\n",
       " 'him',\n",
       " 'mention',\n",
       " 'her',\n",
       " 'under',\n",
       " 'any',\n",
       " 'other',\n",
       " 'name',\n",
       " 'in',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'she',\n",
       " 'eclipses',\n",
       " 'and',\n",
       " 'predominates',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'of',\n",
       " 'her',\n",
       " 'sex',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'that',\n",
       " 'he',\n",
       " 'felt',\n",
       " 'any',\n",
       " 'emotion',\n",
       " 'akin',\n",
       " 'to',\n",
       " 'love',\n",
       " 'for',\n",
       " 'irene',\n",
       " 'adler',\n",
       " 'all',\n",
       " 'emotions',\n",
       " 'and',\n",
       " 'that',\n",
       " 'one',\n",
       " 'particularly',\n",
       " 'were',\n",
       " 'abhorrent',\n",
       " 'to',\n",
       " 'his',\n",
       " 'cold',\n",
       " 'precise',\n",
       " 'but',\n",
       " 'admirably',\n",
       " 'balanced',\n",
       " 'mind',\n",
       " 'he',\n",
       " 'was',\n",
       " 'i',\n",
       " 'take',\n",
       " 'it',\n",
       " 'the',\n",
       " 'most',\n",
       " 'perfect',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'observing',\n",
       " 'machine',\n",
       " 'that',\n",
       " 'the',\n",
       " 'world',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'but',\n",
       " 'as',\n",
       " 'a',\n",
       " 'lover',\n",
       " 'he',\n",
       " 'would',\n",
       " 'have',\n",
       " 'placed',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'a',\n",
       " 'false',\n",
       " 'position',\n",
       " 'he',\n",
       " 'never',\n",
       " 'spoke',\n",
       " 'of',\n",
       " 'the',\n",
       " 'softer',\n",
       " 'passions',\n",
       " 'save',\n",
       " 'with',\n",
       " 'a',\n",
       " 'gibe',\n",
       " 'and',\n",
       " 'a',\n",
       " 'sneer',\n",
       " 'they',\n",
       " 'were',\n",
       " 'admirable',\n",
       " 'things',\n",
       " 'for',\n",
       " 'the',\n",
       " 'observer',\n",
       " 'excellent',\n",
       " 'for',\n",
       " 'drawing',\n",
       " 'the',\n",
       " 'veil',\n",
       " 'from',\n",
       " 'men',\n",
       " 's',\n",
       " 'motives',\n",
       " 'and',\n",
       " 'actions',\n",
       " 'but',\n",
       " 'for',\n",
       " 'the',\n",
       " 'trained',\n",
       " 'reasoner',\n",
       " 'to',\n",
       " 'admit',\n",
       " 'such',\n",
       " 'intrusions',\n",
       " 'into',\n",
       " 'his',\n",
       " 'own',\n",
       " 'delicate',\n",
       " 'and',\n",
       " 'finely',\n",
       " 'adjusted',\n",
       " 'temperament',\n",
       " 'was',\n",
       " 'to',\n",
       " 'introduce',\n",
       " 'a',\n",
       " 'distracting',\n",
       " 'factor',\n",
       " 'which',\n",
       " 'might',\n",
       " 'throw',\n",
       " 'a',\n",
       " 'doubt',\n",
       " 'upon',\n",
       " 'all',\n",
       " 'his',\n",
       " 'mental',\n",
       " 'results',\n",
       " 'grit',\n",
       " 'in',\n",
       " 'a',\n",
       " 'sensitive',\n",
       " 'instrument',\n",
       " 'or',\n",
       " 'a',\n",
       " 'crack',\n",
       " 'in',\n",
       " 'one',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'high',\n",
       " 'power',\n",
       " 'lenses',\n",
       " 'would',\n",
       " 'not',\n",
       " 'be',\n",
       " 'more',\n",
       " 'disturbing',\n",
       " 'than',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'emotion',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nature',\n",
       " 'such',\n",
       " 'as',\n",
       " 'his',\n",
       " 'and',\n",
       " 'yet',\n",
       " 'there',\n",
       " 'was',\n",
       " 'but',\n",
       " 'one',\n",
       " 'woman',\n",
       " 'to',\n",
       " 'him',\n",
       " 'and',\n",
       " 'that',\n",
       " 'woman',\n",
       " 'was',\n",
       " 'the',\n",
       " 'late',\n",
       " 'irene',\n",
       " 'adler',\n",
       " 'of',\n",
       " 'dubious',\n",
       " 'and',\n",
       " 'questionable',\n",
       " 'memory',\n",
       " 'i',\n",
       " 'had',\n",
       " 'seen',\n",
       " 'little',\n",
       " 'of',\n",
       " 'holmes',\n",
       " 'lately',\n",
       " 'my',\n",
       " 'marriage',\n",
       " 'had',\n",
       " 'drifted',\n",
       " 'us',\n",
       " 'away',\n",
       " 'from',\n",
       " 'each',\n",
       " 'other',\n",
       " 'my',\n",
       " 'own',\n",
       " 'complete',\n",
       " 'happiness',\n",
       " 'and',\n",
       " 'the',\n",
       " 'home',\n",
       " 'centred',\n",
       " 'interests',\n",
       " 'which',\n",
       " 'rise',\n",
       " 'up',\n",
       " 'around',\n",
       " 'the',\n",
       " 'man',\n",
       " 'who',\n",
       " 'first',\n",
       " 'finds',\n",
       " 'himself',\n",
       " 'master',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'establishment',\n",
       " 'were',\n",
       " 'sufficient',\n",
       " 'to',\n",
       " 'absorb',\n",
       " 'all',\n",
       " 'my',\n",
       " 'attention',\n",
       " 'while',\n",
       " 'holmes',\n",
       " 'who',\n",
       " 'loathed',\n",
       " 'every',\n",
       " 'form',\n",
       " 'of',\n",
       " 'society',\n",
       " 'with',\n",
       " 'his',\n",
       " 'whole',\n",
       " 'bohemian',\n",
       " 'soul',\n",
       " 'remained',\n",
       " 'in',\n",
       " 'our',\n",
       " 'lodgings',\n",
       " 'in',\n",
       " 'baker',\n",
       " 'street',\n",
       " 'buried',\n",
       " 'among',\n",
       " 'his',\n",
       " 'old',\n",
       " 'books',\n",
       " 'and',\n",
       " 'alternating',\n",
       " 'from',\n",
       " 'week',\n",
       " 'to',\n",
       " 'week',\n",
       " 'between',\n",
       " 'cocaine',\n",
       " 'and',\n",
       " 'ambition',\n",
       " 'the',\n",
       " 'drowsiness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'drug',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fierce',\n",
       " 'energy',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'keen',\n",
       " 'nature',\n",
       " 'he',\n",
       " 'was',\n",
       " 'still',\n",
       " 'as',\n",
       " 'ever',\n",
       " 'deeply',\n",
       " 'attracted',\n",
       " 'by',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'crime',\n",
       " 'and',\n",
       " 'occupied',\n",
       " 'his',\n",
       " 'immense',\n",
       " 'faculties',\n",
       " 'and',\n",
       " 'extraordinary',\n",
       " 'powers',\n",
       " 'of',\n",
       " 'observation',\n",
       " 'in',\n",
       " 'following',\n",
       " 'out',\n",
       " 'those',\n",
       " 'clues',\n",
       " 'and',\n",
       " 'clearing',\n",
       " 'up',\n",
       " 'those',\n",
       " 'mysteries',\n",
       " 'which',\n",
       " 'had',\n",
       " 'been',\n",
       " 'abandoned',\n",
       " 'as',\n",
       " 'hopeless',\n",
       " 'by',\n",
       " 'the',\n",
       " 'official',\n",
       " 'police',\n",
       " 'from',\n",
       " 'time',\n",
       " 'to',\n",
       " 'time',\n",
       " 'i',\n",
       " 'heard',\n",
       " 'some',\n",
       " 'vague',\n",
       " 'account',\n",
       " 'of',\n",
       " 'his',\n",
       " 'doings',\n",
       " 'of',\n",
       " 'his',\n",
       " 'summons',\n",
       " 'to',\n",
       " 'odessa',\n",
       " 'in',\n",
       " 'the',\n",
       " 'case',\n",
       " 'of',\n",
       " 'the',\n",
       " 'trepoff',\n",
       " 'murder',\n",
       " 'of',\n",
       " 'his',\n",
       " 'clearing',\n",
       " 'up',\n",
       " 'of',\n",
       " 'the',\n",
       " 'singular',\n",
       " 'tragedy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'atkinson',\n",
       " 'brothers',\n",
       " 'at',\n",
       " 'trincomalee',\n",
       " 'and',\n",
       " 'finally',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mission',\n",
       " 'which',\n",
       " 'he',\n",
       " 'had',\n",
       " 'accomplished',\n",
       " 'so',\n",
       " 'delicately',\n",
       " 'and',\n",
       " 'successfully',\n",
       " 'for',\n",
       " 'the',\n",
       " 'reigning',\n",
       " 'family',\n",
       " 'of',\n",
       " 'holland',\n",
       " 'beyond',\n",
       " 'these',\n",
       " 'signs',\n",
       " 'of',\n",
       " 'his',\n",
       " 'activity',\n",
       " 'however',\n",
       " 'which',\n",
       " 'i',\n",
       " 'merely',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'all',\n",
       " 'the',\n",
       " 'readers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'daily',\n",
       " 'press',\n",
       " 'i',\n",
       " 'knew',\n",
       " 'little',\n",
       " 'of',\n",
       " 'my',\n",
       " 'former',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'companion',\n",
       " 'one',\n",
       " 'night',\n",
       " 'it',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'twentieth',\n",
       " 'of',\n",
       " 'march',\n",
       " '1888',\n",
       " 'i',\n",
       " 'was',\n",
       " 'returning',\n",
       " 'from',\n",
       " 'a',\n",
       " 'journey',\n",
       " 'to',\n",
       " 'a',\n",
       " 'patient',\n",
       " 'for',\n",
       " 'i',\n",
       " 'had',\n",
       " 'now',\n",
       " 'returned',\n",
       " 'to',\n",
       " 'civil',\n",
       " 'practice',\n",
       " 'when',\n",
       " 'my',\n",
       " 'way',\n",
       " 'led',\n",
       " 'me',\n",
       " 'through',\n",
       " 'baker',\n",
       " 'street',\n",
       " 'as',\n",
       " 'i',\n",
       " 'passed',\n",
       " 'the',\n",
       " 'well',\n",
       " 'remembered',\n",
       " 'door',\n",
       " 'which',\n",
       " 'must',\n",
       " 'always',\n",
       " 'be',\n",
       " 'associated',\n",
       " 'in',\n",
       " 'my',\n",
       " 'mind',\n",
       " 'with',\n",
       " 'my',\n",
       " 'wooing',\n",
       " 'and',\n",
       " 'with',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'incidents',\n",
       " 'of',\n",
       " 'the',\n",
       " 'study',\n",
       " 'in',\n",
       " 'scarlet',\n",
       " 'i',\n",
       " 'was',\n",
       " 'seized',\n",
       " 'with',\n",
       " 'a',\n",
       " 'keen',\n",
       " 'desire',\n",
       " 'to',\n",
       " 'see',\n",
       " 'holmes',\n",
       " 'again',\n",
       " 'and',\n",
       " 'to',\n",
       " 'know',\n",
       " 'how',\n",
       " 'he',\n",
       " 'was',\n",
       " 'employing',\n",
       " 'his',\n",
       " 'extraordinary',\n",
       " 'powers',\n",
       " 'his',\n",
       " 'rooms',\n",
       " 'were',\n",
       " 'brilliantly',\n",
       " 'lit',\n",
       " 'and',\n",
       " 'even',\n",
       " 'as',\n",
       " 'i',\n",
       " 'looked',\n",
       " 'up',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'tall',\n",
       " 'spare',\n",
       " 'figure',\n",
       " 'pass',\n",
       " 'twice',\n",
       " 'in',\n",
       " 'a',\n",
       " 'dark',\n",
       " 'silhouette',\n",
       " 'against',\n",
       " 'the',\n",
       " 'blind',\n",
       " 'he',\n",
       " 'was',\n",
       " 'pacing',\n",
       " 'the',\n",
       " 'room',\n",
       " 'swiftly',\n",
       " 'eagerly',\n",
       " 'with',\n",
       " 'his',\n",
       " 'head',\n",
       " 'sunk',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'chest',\n",
       " 'and',\n",
       " 'his',\n",
       " 'hands',\n",
       " 'clasped',\n",
       " 'behind',\n",
       " 'him',\n",
       " 'to',\n",
       " 'me',\n",
       " 'who',\n",
       " 'knew',\n",
       " 'his',\n",
       " 'every',\n",
       " 'mood',\n",
       " 'and',\n",
       " 'habit',\n",
       " 'his',\n",
       " 'attitude',\n",
       " 'and',\n",
       " 'manner',\n",
       " 'told',\n",
       " 'their',\n",
       " 'own',\n",
       " 'story',\n",
       " 'he',\n",
       " 'was',\n",
       " 'at',\n",
       " 'work',\n",
       " 'again',\n",
       " 'he',\n",
       " 'had',\n",
       " 'risen',\n",
       " 'out',\n",
       " 'of',\n",
       " 'his',\n",
       " 'drug',\n",
       " 'created',\n",
       " 'dreams',\n",
       " 'and',\n",
       " 'was',\n",
       " 'hot',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'scent',\n",
       " 'of',\n",
       " 'some',\n",
       " 'new',\n",
       " 'problem',\n",
       " 'i',\n",
       " 'rang',\n",
       " 'the',\n",
       " 'bell',\n",
       " 'and',\n",
       " 'was',\n",
       " 'shown',\n",
       " 'up',\n",
       " 'to',\n",
       " 'the',\n",
       " 'chamber',\n",
       " 'which',\n",
       " 'had',\n",
       " 'formerly',\n",
       " 'been',\n",
       " 'in',\n",
       " 'part',\n",
       " 'my',\n",
       " 'own',\n",
       " 'his',\n",
       " 'manner',\n",
       " 'was',\n",
       " 'not',\n",
       " 'effusive',\n",
       " 'it',\n",
       " 'seldom',\n",
       " 'was',\n",
       " 'but',\n",
       " 'he',\n",
       " 'was',\n",
       " 'glad',\n",
       " 'i',\n",
       " 'think',\n",
       " 'to',\n",
       " 'see',\n",
       " 'me',\n",
       " 'with',\n",
       " 'hardly',\n",
       " 'a',\n",
       " 'word',\n",
       " 'spoken',\n",
       " 'but',\n",
       " 'with',\n",
       " 'a',\n",
       " 'kindly',\n",
       " 'eye',\n",
       " 'he',\n",
       " 'waved',\n",
       " 'me',\n",
       " 'to',\n",
       " 'an',\n",
       " 'armchair',\n",
       " 'threw',\n",
       " 'across',\n",
       " 'his',\n",
       " 'case',\n",
       " 'of',\n",
       " 'cigars',\n",
       " 'and',\n",
       " 'indicated',\n",
       " 'a',\n",
       " 'spirit',\n",
       " 'case',\n",
       " 'and',\n",
       " 'a',\n",
       " 'gasogene',\n",
       " 'in',\n",
       " 'the',\n",
       " 'corner',\n",
       " 'then',\n",
       " 'he',\n",
       " 'stood',\n",
       " 'before',\n",
       " 'the',\n",
       " 'fire',\n",
       " 'and',\n",
       " 'looked',\n",
       " 'me',\n",
       " 'over',\n",
       " 'in',\n",
       " 'his',\n",
       " 'singular',\n",
       " 'introspective',\n",
       " 'fashion',\n",
       " 'wedlock',\n",
       " 'suits',\n",
       " 'you',\n",
       " 'he',\n",
       " 'remarked',\n",
       " 'i',\n",
       " 'think',\n",
       " 'watson',\n",
       " 'that',\n",
       " 'you',\n",
       " 'have',\n",
       " 'put',\n",
       " 'on',\n",
       " 'seven',\n",
       " 'and',\n",
       " 'a',\n",
       " 'half',\n",
       " 'pounds',\n",
       " 'since',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'you',\n",
       " 'seven',\n",
       " 'i',\n",
       " 'answered',\n",
       " 'indeed',\n",
       " 'i',\n",
       " 'should',\n",
       " 'have',\n",
       " 'thought',\n",
       " 'a',\n",
       " 'little',\n",
       " 'more',\n",
       " 'just',\n",
       " 'a',\n",
       " 'trifle',\n",
       " 'more',\n",
       " 'i',\n",
       " 'fancy',\n",
       " 'watson',\n",
       " 'and',\n",
       " 'in',\n",
       " 'practice',\n",
       " 'again',\n",
       " 'i',\n",
       " 'observe',\n",
       " 'you',\n",
       " 'did',\n",
       " 'not',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'that',\n",
       " 'you',\n",
       " 'intended',\n",
       " 'to',\n",
       " 'go',\n",
       " 'into',\n",
       " 'harness',\n",
       " 'then',\n",
       " 'how',\n",
       " 'do',\n",
       " 'you',\n",
       " 'know',\n",
       " 'i',\n",
       " 'see',\n",
       " 'it',\n",
       " 'i',\n",
       " 'deduce',\n",
       " 'it',\n",
       " 'how',\n",
       " 'do',\n",
       " 'i',\n",
       " 'know',\n",
       " 'that',\n",
       " 'you',\n",
       " 'have',\n",
       " 'been',\n",
       " 'getting',\n",
       " 'yourself',\n",
       " 'very',\n",
       " 'wet',\n",
       " 'lately',\n",
       " 'and',\n",
       " 'that',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'most',\n",
       " 'clumsy',\n",
       " 'and',\n",
       " 'careless',\n",
       " 'servant',\n",
       " 'girl',\n",
       " 'my',\n",
       " 'dear',\n",
       " 'holmes',\n",
       " 'said',\n",
       " 'i',\n",
       " 'this',\n",
       " 'is',\n",
       " 'too',\n",
       " 'much',\n",
       " 'you',\n",
       " 'would',\n",
       " 'certainly',\n",
       " 'have',\n",
       " 'been',\n",
       " 'burned',\n",
       " 'had',\n",
       " 'you',\n",
       " 'lived',\n",
       " 'a',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "words = tokenizer.tokenize(text)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b74e950",
   "metadata": {},
   "source": [
    "## Feature Engineering in our data:\n",
    "For this purpose, we will require a dictionary with each word in the data within the list of unique words as the key, and it’s significant portions as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eecd8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = np.unique(words)\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86d84b",
   "metadata": {},
   "source": [
    "### Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "123b7b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 's', 'the', 'adventures']\n",
      "of\n"
     ]
    }
   ],
   "source": [
    "word_len = 5\n",
    "prev_words = []\n",
    "next_words = []\n",
    "for i in range(len(words) - word_len):\n",
    "    prev_words.append(words[i:i + word_len])\n",
    "    next_words.append(words[i + word_len])\n",
    "print(prev_words[0])\n",
    "print(next_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff6542",
   "metadata": {},
   "source": [
    "**We will create two numpy arrays x for storing the features and y for storing its corresponding label. We will iterate x and y if the word is available so that the corresponding position becomes 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f80df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(prev_words), word_len, len(unique_words)), dtype=bool)\n",
    "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)\n",
    "for i, each_words in enumerate(prev_words):\n",
    "    for j, each_word in enumerate(each_words):\n",
    "        X[i, j, unique_word_index[each_word]] = 1\n",
    "    Y[i, unique_word_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef3a0b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "#a look at a single sequence of words\n",
    "print(X[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa63b6e",
   "metadata": {},
   "source": [
    "## Building the Recurrent Neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f162ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the LSTM model,which is a very powerful RNN.\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(word_len, len(unique_words))))\n",
    "model.add(Dense(len(unique_words)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ffb0b1",
   "metadata": {},
   "source": [
    "## Training the Next Word Prediction Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e270134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "307/811 [==========>...................] - ETA: 1:57 - loss: 6.3470 - accuracy: 0.0802"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acaf100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model for future \n",
    "model.save('keras_next_word_model.h5')\n",
    "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
    "model = load_model('keras_next_word_model.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49496a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "keras.utils.plot_model(model, to_file='model.png', show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4253b2",
   "metadata": {},
   "source": [
    "## Evaluating the Next Word Prediction Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604bde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model accuracy\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44362eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model loss\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe63b36",
   "metadata": {},
   "source": [
    "## Testing Next Word Prediction Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6217a495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, word_len, len(unique_words)))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        print(word)\n",
    "        x[0, t, unique_word_index[word]] = 1\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b63f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_input(\"It is not a lack\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2077190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, word_len, len(unique_words)))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        print(word)\n",
    "        x[0, t, unique_word_index[word]] = 1\n",
    "    return x\n",
    "prepare_input(\"It is not a lack\".lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ace31",
   "metadata": {},
   "source": [
    "## To choose the best possible n words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af005a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125cfcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completion(text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        \n",
    "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
    "            return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6eb13",
   "metadata": {},
   "source": [
    "## Function for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf317b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completions(text, n=3):\n",
    "    if text == \"\":\n",
    "        return(\"0\")\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [unique_words[idx] for idx in next_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc60e0d",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q =  \"Light the candle instead of cursuing darkness\"\n",
    "print(\"correct sentence: \",q)\n",
    "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
    "print(\"Sequence: \",seq)\n",
    "print(\"next possible words: \", predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb1686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
